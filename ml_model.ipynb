{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml-model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNR/XLIFUHYfZQ6J9mPwPX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcellinusc/solar-radiation/blob/model-building/ml_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4PdA4irqEaK",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division\n",
        "from __future__ import print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbg1PDRauaer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "cellView": "form",
        "outputId": "7067f6d1-4cdf-473b-dfba-c219a4dfda76"
      },
      "source": [
        "#@title Import relevant modules\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print('Imported')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Imported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBYWKNU-xda8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "d2dd9e38-df4e-47bd-d2d6-f52ac63b9e4f"
      },
      "source": [
        "#@title Load raw dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/marcellinusc/solar-radiation/data-prep/datasets.csv')\n",
        "print('Dataset length:', str(len(data)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length: 32686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T2D3iiPyA9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "445c9e15-978c-4b43-accb-4b374e7d9919"
      },
      "source": [
        "#@title Exclude raw data between sunset-sunrise\n",
        "\n",
        "daylight = [data['Time'].values[x] > data['Sunrise'].values[x]\n",
        "            and data['Time'].values[x] < data['Sunset'].values[x]\n",
        "            for x in range(len(data))]\n",
        "data['Daylight'] = daylight\n",
        "data['Daylight'] = data['Daylight'].astype('float')\n",
        "\n",
        "# Clean raw dataset from daylight value of 0\n",
        "data = data[data.Daylight != 0]\n",
        "\n",
        "print('Dataset length:', str(len(data)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length: 15608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCXskDyrOKil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "c4b49123-b143-4b34-bdbd-9d7c165b4cb0"
      },
      "source": [
        "#@title Convert UNIX time format to UTC\n",
        "\n",
        "data[\"TimeConversion\"] = pd.to_datetime(data[\"Time\"], format=\"%H:%M:%S\")\n",
        "\n",
        "# Get the month of the year and the day of the month\n",
        "data[\"Month\"] = pd.to_datetime(data[\"UNIXTime\"].astype(int),\n",
        "                               unit=\"s\").dt.month\n",
        "data[\"Day\"] = pd.to_datetime(data[\"UNIXTime\"].astype(int),\n",
        "                             unit=\"s\").dt.day \n",
        "\n",
        "# Get the hour and the minute of the day\n",
        "data[\"Hour\"] = pd.to_datetime(data[\"TimeConversion\"],\n",
        "                              format=\"%H:%M:%S\").dt.hour\n",
        "data[\"Minute\"] = pd.to_datetime(data[\"TimeConversion\"],\n",
        "                              format=\"%H:%M:%S\").dt.minute\n",
        "\n",
        "print('Converted')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzjfIldM8FeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "cellView": "form",
        "outputId": "d8ce1f34-8aca-4f3d-ee81-187063bdb53a"
      },
      "source": [
        "#@title Divide clean dataset into training set and test set\n",
        "\n",
        "# Sort dataset in descending order from the latest to the earliest\n",
        "data['Data'] = pd.to_datetime(data['Data'])\n",
        "data = data.sort_values(by=['Data', 'Time'], ascending=False)\n",
        "\n",
        "# Percentage of dataset to be considered as test set\n",
        "test_split = 0.2\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "# Shuffle training set\n",
        "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
        "\n",
        "print('Training set length:', str(len(data_train)),\n",
        "      '\\nTest set length:', str(len(data_test)))\n",
        "\n",
        "# Remove column 'Daylight' from dataframe\n",
        "data_train = data_train.drop(columns='Daylight')\n",
        "data_test = data_test.drop(columns='Daylight')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set length: 12486 \n",
            "Test set length: 3122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UontCGSpBWgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "9d026782-d164-4491-8dc7-d9f37527c2ce"
      },
      "source": [
        "#@title Normalize values\n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_train_std = data_train.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_train_norm = (data_train.select_dtypes(include=['float64', 'int64']) \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_test_std = data_test.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_test_norm = (data_test.select_dtypes(include=['float64', 'int64'])\n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN96BHt1Mv9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "3eca5db3-993e-4898-9817-b08aad5cc6c4"
      },
      "source": [
        "#@title Represent features as a floating-point value\n",
        "\n",
        "feature_columns = []\n",
        "\n",
        "temperature = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature)\n",
        "\n",
        "pressure = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure)\n",
        "\n",
        "humidity = tf.feature_column.numeric_column(\"Humidity\")\n",
        "feature_columns.append(humidity)\n",
        "\n",
        "wdirection = tf.feature_column.numeric_column(\"WindDirection\")\n",
        "feature_columns.append(wdirection)\n",
        "\n",
        "wspeed = tf.feature_column.numeric_column(\"WindSpeed\")\n",
        "feature_columns.append(wspeed)\n",
        "\n",
        "#sunrise = tf.feature_column.numeric_column(\"Sunrise\")\n",
        "#feature_columns.append(sunrise)\n",
        "\n",
        "#sunset = tf.feature_column.numeric_column(\"Sunset\")\n",
        "#feature_columns.append(sunset)\n",
        "\n",
        "#month = tf.feature_column.numeric_column(\"Month\")\n",
        "#feature_columns.append(month)\n",
        "\n",
        "#day = tf.feature_column.numeric_column(\"Day\")\n",
        "#feature_columns.append(day)\n",
        "\n",
        "hour = tf.feature_column.numeric_column(\"Hour\")\n",
        "feature_columns.append(hour)\n",
        "\n",
        "#minute = tf.feature_column.numeric_column(\"Minute\")\n",
        "#feature_columns.append(minute)\n",
        "\n",
        "# Convert the list of feature columns into a layer that \n",
        "# later will be fed into the model. \n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "print('Represented')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Represented\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqJhB8lwRCPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "54aa6bb7-4b4a-4cc7-9b9d-ea4f1b433e83"
      },
      "source": [
        "#@title Define plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse_training, rmse_validation):\n",
        "  \"\"\"Plot loss vs epoch in a graph\"\"\"\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Root Mean Squared Error')\n",
        "\n",
        "  plt.plot(epochs[1:], rmse_training[1:], label='Training Loss')\n",
        "  plt.plot(epochs[1:], rmse_validation[1:], label='Validation Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  merged_rmse_lists = rmse_training[1:] + rmse_validation[1:]\n",
        "  highest_loss = max(merged_rmse_lists)\n",
        "  lowest_loss = min(merged_rmse_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print('Defined')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_22JvNLTAUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "2937d96e-621a-4904-88f8-7f1807ba344f"
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "\n",
        "def create_model(learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=learning_rate),\n",
        "                loss='mean_squared_error',\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  \n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size,\n",
        "                label_name, validation_split):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, \n",
        "                      shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist['root_mean_squared_error']\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print('Defined')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tTmKEHCUlJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "both",
        "outputId": "758a7070-1913-4bed-d86e-5919b68c091d"
      },
      "source": [
        "#@title Train model as linear regression\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "batch_size = 1024\n",
        "validation_split = 0.5\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "# Establish the model's topography.\n",
        "model = create_model(learning_rate, feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, rmse, history = train_model(model, data_train_norm, epochs, batch_size,\n",
        "                                    label_name, validation_split=validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "# Isolate the label\n",
        "test_label = np.array(test_features.pop(label_name))\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "model.evaluate(x=test_features, y=test_label, batch_size=batch_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 2.9402 - root_mean_squared_error: 1.7289 - val_loss: 2.4078 - val_root_mean_squared_error: 1.5750\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.2853 - root_mean_squared_error: 1.5225 - val_loss: 1.9956 - val_root_mean_squared_error: 1.4317\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.9131 - root_mean_squared_error: 1.3897 - val_loss: 1.6971 - val_root_mean_squared_error: 1.3185\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.6103 - root_mean_squared_error: 1.2826 - val_loss: 1.4683 - val_root_mean_squared_error: 1.2242\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.3592 - root_mean_squared_error: 1.1938 - val_loss: 1.2928 - val_root_mean_squared_error: 1.1466\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.2597 - root_mean_squared_error: 1.1194 - val_loss: 1.1364 - val_root_mean_squared_error: 1.0729\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.0951 - root_mean_squared_error: 1.0505 - val_loss: 1.0122 - val_root_mean_squared_error: 1.0104\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.9731 - root_mean_squared_error: 0.9907 - val_loss: 0.9080 - val_root_mean_squared_error: 0.9549\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8637 - root_mean_squared_error: 0.9386 - val_loss: 0.8292 - val_root_mean_squared_error: 0.9101\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7897 - root_mean_squared_error: 0.8953 - val_loss: 0.7614 - val_root_mean_squared_error: 0.8704\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7510 - root_mean_squared_error: 0.8598 - val_loss: 0.7101 - val_root_mean_squared_error: 0.8388\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6681 - root_mean_squared_error: 0.8305 - val_loss: 0.6683 - val_root_mean_squared_error: 0.8129\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6670 - root_mean_squared_error: 0.8081 - val_loss: 0.6361 - val_root_mean_squared_error: 0.7926\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6322 - root_mean_squared_error: 0.7884 - val_loss: 0.6050 - val_root_mean_squared_error: 0.7721\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5947 - root_mean_squared_error: 0.7699 - val_loss: 0.5864 - val_root_mean_squared_error: 0.7588\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5643 - root_mean_squared_error: 0.7554 - val_loss: 0.5671 - val_root_mean_squared_error: 0.7457\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5424 - root_mean_squared_error: 0.7443 - val_loss: 0.5523 - val_root_mean_squared_error: 0.7356\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5453 - root_mean_squared_error: 0.7343 - val_loss: 0.5446 - val_root_mean_squared_error: 0.7289\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5336 - root_mean_squared_error: 0.7268 - val_loss: 0.5374 - val_root_mean_squared_error: 0.7238\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5383 - root_mean_squared_error: 0.7219 - val_loss: 0.5308 - val_root_mean_squared_error: 0.7195\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5059 - root_mean_squared_error: 0.7187 - val_loss: 0.5312 - val_root_mean_squared_error: 0.7187\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5084 - root_mean_squared_error: 0.7166 - val_loss: 0.5277 - val_root_mean_squared_error: 0.7165\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5288 - root_mean_squared_error: 0.7156 - val_loss: 0.5286 - val_root_mean_squared_error: 0.7175\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5110 - root_mean_squared_error: 0.7155 - val_loss: 0.5265 - val_root_mean_squared_error: 0.7156\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5179 - root_mean_squared_error: 0.7152 - val_loss: 0.5341 - val_root_mean_squared_error: 0.7195\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5099 - root_mean_squared_error: 0.7152 - val_loss: 0.5343 - val_root_mean_squared_error: 0.7201\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5109 - root_mean_squared_error: 0.7147 - val_loss: 0.5320 - val_root_mean_squared_error: 0.7187\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5060 - root_mean_squared_error: 0.7153 - val_loss: 0.5299 - val_root_mean_squared_error: 0.7177\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5112 - root_mean_squared_error: 0.7150 - val_loss: 0.5353 - val_root_mean_squared_error: 0.7204\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4959 - root_mean_squared_error: 0.7153 - val_loss: 0.5343 - val_root_mean_squared_error: 0.7199\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5005 - root_mean_squared_error: 0.7151 - val_loss: 0.5336 - val_root_mean_squared_error: 0.7193\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5075 - root_mean_squared_error: 0.7151 - val_loss: 0.5297 - val_root_mean_squared_error: 0.7168\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5125 - root_mean_squared_error: 0.7148 - val_loss: 0.5304 - val_root_mean_squared_error: 0.7180\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5197 - root_mean_squared_error: 0.7151 - val_loss: 0.5325 - val_root_mean_squared_error: 0.7189\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5342 - root_mean_squared_error: 0.7148 - val_loss: 0.5352 - val_root_mean_squared_error: 0.7205\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5130 - root_mean_squared_error: 0.7152 - val_loss: 0.5330 - val_root_mean_squared_error: 0.7187\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5236 - root_mean_squared_error: 0.7149 - val_loss: 0.5294 - val_root_mean_squared_error: 0.7172\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5204 - root_mean_squared_error: 0.7151 - val_loss: 0.5312 - val_root_mean_squared_error: 0.7183\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5201 - root_mean_squared_error: 0.7148 - val_loss: 0.5296 - val_root_mean_squared_error: 0.7171\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5086 - root_mean_squared_error: 0.7155 - val_loss: 0.5287 - val_root_mean_squared_error: 0.7164\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5065 - root_mean_squared_error: 0.7154 - val_loss: 0.5314 - val_root_mean_squared_error: 0.7182\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5252 - root_mean_squared_error: 0.7149 - val_loss: 0.5302 - val_root_mean_squared_error: 0.7178\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5029 - root_mean_squared_error: 0.7152 - val_loss: 0.5282 - val_root_mean_squared_error: 0.7164\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5144 - root_mean_squared_error: 0.7155 - val_loss: 0.5267 - val_root_mean_squared_error: 0.7159\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5103 - root_mean_squared_error: 0.7151 - val_loss: 0.5287 - val_root_mean_squared_error: 0.7164\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5101 - root_mean_squared_error: 0.7150 - val_loss: 0.5278 - val_root_mean_squared_error: 0.7166\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5206 - root_mean_squared_error: 0.7152 - val_loss: 0.5253 - val_root_mean_squared_error: 0.7149\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5041 - root_mean_squared_error: 0.7151 - val_loss: 0.5282 - val_root_mean_squared_error: 0.7162\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5130 - root_mean_squared_error: 0.7152 - val_loss: 0.5310 - val_root_mean_squared_error: 0.7184\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5044 - root_mean_squared_error: 0.7150 - val_loss: 0.5295 - val_root_mean_squared_error: 0.7170\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5008 - root_mean_squared_error: 0.7153 - val_loss: 0.5298 - val_root_mean_squared_error: 0.7173\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5151 - root_mean_squared_error: 0.7150 - val_loss: 0.5347 - val_root_mean_squared_error: 0.7199\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5119 - root_mean_squared_error: 0.7152 - val_loss: 0.5336 - val_root_mean_squared_error: 0.7194\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5008 - root_mean_squared_error: 0.7148 - val_loss: 0.5322 - val_root_mean_squared_error: 0.7186\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5171 - root_mean_squared_error: 0.7150 - val_loss: 0.5325 - val_root_mean_squared_error: 0.7195\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5219 - root_mean_squared_error: 0.7156 - val_loss: 0.5331 - val_root_mean_squared_error: 0.7196\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5178 - root_mean_squared_error: 0.7155 - val_loss: 0.5322 - val_root_mean_squared_error: 0.7189\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5301 - root_mean_squared_error: 0.7154 - val_loss: 0.5350 - val_root_mean_squared_error: 0.7204\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5225 - root_mean_squared_error: 0.7150 - val_loss: 0.5285 - val_root_mean_squared_error: 0.7165\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5045 - root_mean_squared_error: 0.7151 - val_loss: 0.5293 - val_root_mean_squared_error: 0.7169\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5248 - root_mean_squared_error: 0.7152 - val_loss: 0.5302 - val_root_mean_squared_error: 0.7180\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5138 - root_mean_squared_error: 0.7152 - val_loss: 0.5304 - val_root_mean_squared_error: 0.7172\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5309 - root_mean_squared_error: 0.7149 - val_loss: 0.5323 - val_root_mean_squared_error: 0.7190\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5197 - root_mean_squared_error: 0.7152 - val_loss: 0.5291 - val_root_mean_squared_error: 0.7166\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5136 - root_mean_squared_error: 0.7151 - val_loss: 0.5284 - val_root_mean_squared_error: 0.7161\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5077 - root_mean_squared_error: 0.7151 - val_loss: 0.5302 - val_root_mean_squared_error: 0.7173\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5221 - root_mean_squared_error: 0.7153 - val_loss: 0.5288 - val_root_mean_squared_error: 0.7168\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5082 - root_mean_squared_error: 0.7150 - val_loss: 0.5344 - val_root_mean_squared_error: 0.7200\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5011 - root_mean_squared_error: 0.7149 - val_loss: 0.5309 - val_root_mean_squared_error: 0.7179\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5049 - root_mean_squared_error: 0.7149 - val_loss: 0.5286 - val_root_mean_squared_error: 0.7168\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5086 - root_mean_squared_error: 0.7148 - val_loss: 0.5351 - val_root_mean_squared_error: 0.7204\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4990 - root_mean_squared_error: 0.7151 - val_loss: 0.5276 - val_root_mean_squared_error: 0.7160\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5111 - root_mean_squared_error: 0.7151 - val_loss: 0.5293 - val_root_mean_squared_error: 0.7171\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5006 - root_mean_squared_error: 0.7152 - val_loss: 0.5316 - val_root_mean_squared_error: 0.7183\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5266 - root_mean_squared_error: 0.7155 - val_loss: 0.5285 - val_root_mean_squared_error: 0.7164\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5123 - root_mean_squared_error: 0.7152 - val_loss: 0.5272 - val_root_mean_squared_error: 0.7159\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5108 - root_mean_squared_error: 0.7153 - val_loss: 0.5308 - val_root_mean_squared_error: 0.7183\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5049 - root_mean_squared_error: 0.7150 - val_loss: 0.5311 - val_root_mean_squared_error: 0.7183\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5052 - root_mean_squared_error: 0.7152 - val_loss: 0.5276 - val_root_mean_squared_error: 0.7162\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5073 - root_mean_squared_error: 0.7151 - val_loss: 0.5368 - val_root_mean_squared_error: 0.7214\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4988 - root_mean_squared_error: 0.7158 - val_loss: 0.5306 - val_root_mean_squared_error: 0.7176\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5103 - root_mean_squared_error: 0.7150 - val_loss: 0.5318 - val_root_mean_squared_error: 0.7182\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5116 - root_mean_squared_error: 0.7150 - val_loss: 0.5285 - val_root_mean_squared_error: 0.7164\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5175 - root_mean_squared_error: 0.7148 - val_loss: 0.5313 - val_root_mean_squared_error: 0.7179\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5024 - root_mean_squared_error: 0.7148 - val_loss: 0.5322 - val_root_mean_squared_error: 0.7186\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5148 - root_mean_squared_error: 0.7152 - val_loss: 0.5276 - val_root_mean_squared_error: 0.7161\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5201 - root_mean_squared_error: 0.7149 - val_loss: 0.5341 - val_root_mean_squared_error: 0.7199\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5044 - root_mean_squared_error: 0.7154 - val_loss: 0.5303 - val_root_mean_squared_error: 0.7173\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4991 - root_mean_squared_error: 0.7151 - val_loss: 0.5286 - val_root_mean_squared_error: 0.7164\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5065 - root_mean_squared_error: 0.7149 - val_loss: 0.5284 - val_root_mean_squared_error: 0.7166\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5077 - root_mean_squared_error: 0.7149 - val_loss: 0.5333 - val_root_mean_squared_error: 0.7196\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5158 - root_mean_squared_error: 0.7151 - val_loss: 0.5267 - val_root_mean_squared_error: 0.7154\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4970 - root_mean_squared_error: 0.7150 - val_loss: 0.5276 - val_root_mean_squared_error: 0.7161\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5358 - root_mean_squared_error: 0.7150 - val_loss: 0.5302 - val_root_mean_squared_error: 0.7178\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4984 - root_mean_squared_error: 0.7156 - val_loss: 0.5266 - val_root_mean_squared_error: 0.7156\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5065 - root_mean_squared_error: 0.7153 - val_loss: 0.5268 - val_root_mean_squared_error: 0.7153\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5169 - root_mean_squared_error: 0.7151 - val_loss: 0.5292 - val_root_mean_squared_error: 0.7171\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5038 - root_mean_squared_error: 0.7156 - val_loss: 0.5277 - val_root_mean_squared_error: 0.7163\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5089 - root_mean_squared_error: 0.7149 - val_loss: 0.5267 - val_root_mean_squared_error: 0.7154\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4968 - root_mean_squared_error: 0.7148 - val_loss: 0.5280 - val_root_mean_squared_error: 0.7163\n",
            "0.8077954053878784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4858 - root_mean_squared_error: 0.7276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4858439564704895, 0.727607250213623]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}